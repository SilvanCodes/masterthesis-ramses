{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60f85605-2488-49f1-8db7-86b6b3ca1939",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from evaluate import load  # Hugging Faceâ€™s metrics hub\n",
    "\n",
    "import gpn.model\n",
    "from transformers import AutoModel, AutoModelForMaskedLM, AutoTokenizer, DataCollatorForLanguageModeling\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e267077-2285-4b1e-b22a-958c2964ff13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dilation_schedule=[1, 3, 9, 27, 81, 243, 1, 3, 9, 27, 81, 243, 1, 3, 9, 27, 81, 243]\n"
     ]
    }
   ],
   "source": [
    "# dataset_name = \"sbuedenb/small_beetle_dataset\"\n",
    "# model_name   = \"sbuedenb/beetle-gpn\" # v1: Top-1 accuracy: 51.8759% (validation) , v2: 53.0181%\n",
    "# model_name   = \"sbuedenb/beetle-gpn-wide\" # Top-1 accuracy: 53.3793% (validation)\n",
    "\n",
    "\n",
    "# model_name   = \"sbuedenb/beetle-gpn-wide-reduced\" # Top-1 accuracy: 51.8314%\n",
    "model_name   = \"/home/sbuedenb/models/long-wide-cosine/\"\n",
    "dataset_name = \"sbuedenb/big_beetle_dataset\"\n",
    "# model_name   = \"songlab/gpn-brassicales\"\n",
    "# (on brassicales) Top-1 accuracy: 53.8563% (validation), Top-1 accuracy: 53.2370% (test)\n",
    "# (on cucujiformia) Top-1 accuracy: 42.8384%\n",
    "\n",
    "# dataset_name = \"songlab/genomes-brassicales-balanced-v1\"\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model     = AutoModelForMaskedLM.from_pretrained(model_name, local_files_only=True).eval()\n",
    "dataset   = load_dataset(dataset_name, split=\"validation\")   # or \"validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6433c893-2a80-4cbb-8de2-ca6d9e5146c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device);\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f106fb0b-a6d3-4293-a01a-4f1d0bf8f495",
   "metadata": {},
   "source": [
    "# Top-1 accuracy on sbuedenb/big_beetle_dataset\n",
    "Model | Accuracy (eval) | Accuracy (test)\n",
    "-|-|-\n",
    "songlab/gpn-brassicales| 42.7848% | 42.9517%\n",
    "sbuedenb/beetle-gpn | 51.4824% | 56.0279%\n",
    "sbuedenb/beetle-gpn-wide-reduced | **51.8868%** | **56.2513%**\n",
    "sbuedenb/long-wide-cosine | 52.01% +- 0.63% | 55.70 +- 1.26%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c325a509-25c5-4745-b5ef-397972653aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(batch):\n",
    "    res = tokenizer(\n",
    "        batch[\"seq\"],\n",
    "        return_special_tokens_mask=True,\n",
    "        padding=False,\n",
    "        truncation=False,\n",
    "        return_token_type_ids=False,\n",
    "    )\n",
    "    return res\n",
    "\n",
    "tokenized = dataset.map(tokenize_function, batched=True, remove_columns=[\"seq\", \"assembly\", \"chrom\", \"strand\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49e582e6-570f-427f-8ed1-40e0f6348211",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=True,\n",
    "    mlm_probability=0.15,   # standard BERT mask-ratio\n",
    "    seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c84a8ebc-d945-4f9f-b1ad-b7f532c83cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(\n",
    "    tokenized,\n",
    "    batch_size=256,\n",
    "    shuffle=False,\n",
    "    collate_fn=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c215eb9e-190c-4423-a43b-0ace78fe2fac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7efebdf72b6341eb856fcc1bce647463",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "evaluating:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy: 52.01% | Avg loss: 1.08\n"
     ]
    }
   ],
   "source": [
    "accuracy = load(\"accuracy\")\n",
    "\n",
    "total_loss   = 0.0        # sum of per-token loss\n",
    "total_tokens = 0          # number of tokens that contributed\n",
    "\n",
    "loss_fct = torch.nn.CrossEntropyLoss(ignore_index=-100, reduction=\"sum\")\n",
    "\n",
    "for batch in tqdm(loader, desc=\"evaluating\"):\n",
    "    input_ids  = batch[\"input_ids\"].to(device)\n",
    "    labels     = batch[\"labels\"].to(device)         # -100 where no mask\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_ids=input_ids).logits\n",
    "\n",
    "    preds = logits.argmax(dim=-1)\n",
    "\n",
    "    # Select only the masked positions\n",
    "    mask = labels != -100\n",
    "    accuracy.add_batch(        \n",
    "        predictions=preds[mask],\n",
    "        references=labels[mask],\n",
    "    )\n",
    "\n",
    "    # flatten so CrossEntropyLoss sees (N_tokens, vocab)\n",
    "    loss = loss_fct(\n",
    "        logits.view(-1, logits.size(-1)),\n",
    "        labels.view(-1)\n",
    "    )\n",
    "\n",
    "    total_loss   += loss.item()\n",
    "    total_tokens += mask.sum().item()        # number of real tokens in this batch\n",
    "\n",
    "avg_loss = total_loss / total_tokens         # per-token loss\n",
    "top1 = accuracy.compute()\n",
    "\n",
    "print(f\"Top-1 accuracy: {top1['accuracy']:.2%} | Avg loss: {avg_loss:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b23e077-72c0-4cd5-9df7-6f6b2c501442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.5569858133325299}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32f37407-0045-4ebb-ba87-844f0fda4ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10381"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78eeab92-f922-4eb5-a752-402ac2410962",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# 1.64 (90%)\n",
    "# 1.96 (95%)\n",
    "# 2.33 (98%)\n",
    "# 2.58 (99%)\n",
    "z = 2.58\n",
    "n = len(dataset)\n",
    "acc = top1['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f14a3e5-a5ec-42e5-b7c1-f9d2f5f6b365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99% confidence interval: 1.26%\n"
     ]
    }
   ],
   "source": [
    "interval = z * math.sqrt( (acc * (1 - acc)) / n)\n",
    "interval\n",
    "\n",
    "print(f\"99% confidence interval: {interval:.2%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
