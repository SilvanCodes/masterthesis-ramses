{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9244a4f8-16ef-49b1-8780-c5ee2664d185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapt nuleotide_dependency_maps (NDMs) to Genomic Pre-trained Network (GPN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567ae76e-d7b6-466f-b9f8-c852f12699b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# gpn specific\n",
    "import gpn.model\n",
    "from transformers import AutoModel, AutoModelForMaskedLM, AutoTokenizer\n",
    "\n",
    "# ndm spcific\n",
    "from transformers import DefaultDataCollator\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52608a5-4a31-4605-aea5-146f84443ad9",
   "metadata": {},
   "source": [
    "model_path = \"songlab/gpn-brassicales\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4c985e-b2c3-4bef-829e-903dbc54f92e",
   "metadata": {},
   "source": [
    "Example region: chr5:3566900-3567600\n",
    "\n",
    "[UCSC Genome Browser view](https://genome.ucsc.edu/cgi-bin/hgTracks?db=hub_2660163_GCF_000001735.4&lastVirtModeType=default&lastVirtModeExtraState=&virtModeType=default&virtMode=0&nonVirtPosition=&position=chr5%3A3566900%2D3567600&hgsid=1597075775_CFnbwi2A0U0D8AuOgfJ0LsbUXnOb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "428bd3b5-db81-4e0c-bb89-a349f2263ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "700"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq = \"CGGGTTAAAAATCTAGTTGTTATTATTAAAGGAAATAAAATATCCTCATAAAACAATTTGTTGTAATCTATCTTTGGGCTAATGTTCTTATCCTACAAGACGAACCCTGACCGTATTCGTCGTAGAAAAAAAATTGCTTCGATCCCATCATTGAGTTCAATAATCGGCGCACAAAGGCCGATTCATAAAAACTCTAGGCCCATTAAAGTAAAGCCCATTCTCAACCCTATCCAGTCTCCCTGTATATATATATTTACGACACCAACCCAGCGTTGATATTTAATTTTCTTCAGTCAGAGATTTCGAAACCCTAGTCGATTTCGAGATCCAACTAACTCTGCTCCTTATCTCAGGTAAAATTCTCGCTCGAGAACTCAATTGCTTATCCAAAGTTCCAACTGAAGATGCTTTCCTACTGAATCTTAGGTTAATGTTTTGGATTTGGAATCTTACCCGAAATTTCTCTGCAGCTTGTTGAATTTGCGAAGTATGGGAGACGCTAGAGACAACGAAGCCTACGAGGAGGAGCTCTTGGACTATGAAGAAGAAGACGAGAAGGTCCCAGATTCTGGAAACAAAGTTAACGGCGAAGCTGTGAAAAAGTGAGTTTTATGGTTTCCTCGATATGTTTCATGTATACTACTGTGTGTTTAAATTTGTCGATTCTTAGATTACTACTTGATAACAAGTAGCAGTATGT\"\n",
    "len(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31e73af9-c347-4b82-94c7-96b625e3d0d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'c': 4, 'a': 3, 'g': 5, '[PAD]': 0, 't': 6, '[UNK]': 2, '[MASK]': 1}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "tokenizer.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce7a3e70-bd10-4092-8752-a055dec99de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNetModel(\n",
       "  (embedding): GPNEmbedding()\n",
       "  (encoder): Sequential(\n",
       "    (0): ConvLayer(\n",
       "      (conv): Sequential(\n",
       "        (0): TransposeLayer()\n",
       "        (1): Conv1d(512, 512, kernel_size=(9,), stride=(1,), padding=same)\n",
       "        (2): TransposeLayer()\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ffn): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ConvLayer(\n",
       "      (conv): Sequential(\n",
       "        (0): TransposeLayer()\n",
       "        (1): Conv1d(512, 512, kernel_size=(9,), stride=(1,), padding=same, dilation=(2,))\n",
       "        (2): TransposeLayer()\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ffn): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (2): ConvLayer(\n",
       "      (conv): Sequential(\n",
       "        (0): TransposeLayer()\n",
       "        (1): Conv1d(512, 512, kernel_size=(9,), stride=(1,), padding=same, dilation=(4,))\n",
       "        (2): TransposeLayer()\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ffn): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (3): ConvLayer(\n",
       "      (conv): Sequential(\n",
       "        (0): TransposeLayer()\n",
       "        (1): Conv1d(512, 512, kernel_size=(9,), stride=(1,), padding=same, dilation=(8,))\n",
       "        (2): TransposeLayer()\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ffn): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (4): ConvLayer(\n",
       "      (conv): Sequential(\n",
       "        (0): TransposeLayer()\n",
       "        (1): Conv1d(512, 512, kernel_size=(9,), stride=(1,), padding=same, dilation=(16,))\n",
       "        (2): TransposeLayer()\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ffn): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (5): ConvLayer(\n",
       "      (conv): Sequential(\n",
       "        (0): TransposeLayer()\n",
       "        (1): Conv1d(512, 512, kernel_size=(9,), stride=(1,), padding=same, dilation=(32,))\n",
       "        (2): TransposeLayer()\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ffn): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (6): ConvLayer(\n",
       "      (conv): Sequential(\n",
       "        (0): TransposeLayer()\n",
       "        (1): Conv1d(512, 512, kernel_size=(9,), stride=(1,), padding=same)\n",
       "        (2): TransposeLayer()\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ffn): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (7): ConvLayer(\n",
       "      (conv): Sequential(\n",
       "        (0): TransposeLayer()\n",
       "        (1): Conv1d(512, 512, kernel_size=(9,), stride=(1,), padding=same, dilation=(2,))\n",
       "        (2): TransposeLayer()\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ffn): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (8): ConvLayer(\n",
       "      (conv): Sequential(\n",
       "        (0): TransposeLayer()\n",
       "        (1): Conv1d(512, 512, kernel_size=(9,), stride=(1,), padding=same, dilation=(4,))\n",
       "        (2): TransposeLayer()\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ffn): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (9): ConvLayer(\n",
       "      (conv): Sequential(\n",
       "        (0): TransposeLayer()\n",
       "        (1): Conv1d(512, 512, kernel_size=(9,), stride=(1,), padding=same, dilation=(8,))\n",
       "        (2): TransposeLayer()\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ffn): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (10): ConvLayer(\n",
       "      (conv): Sequential(\n",
       "        (0): TransposeLayer()\n",
       "        (1): Conv1d(512, 512, kernel_size=(9,), stride=(1,), padding=same, dilation=(16,))\n",
       "        (2): TransposeLayer()\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ffn): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (11): ConvLayer(\n",
       "      (conv): Sequential(\n",
       "        (0): TransposeLayer()\n",
       "        (1): Conv1d(512, 512, kernel_size=(9,), stride=(1,), padding=same, dilation=(32,))\n",
       "        (2): TransposeLayer()\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ffn): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (12): ConvLayer(\n",
       "      (conv): Sequential(\n",
       "        (0): TransposeLayer()\n",
       "        (1): Conv1d(512, 512, kernel_size=(9,), stride=(1,), padding=same)\n",
       "        (2): TransposeLayer()\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ffn): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (13): ConvLayer(\n",
       "      (conv): Sequential(\n",
       "        (0): TransposeLayer()\n",
       "        (1): Conv1d(512, 512, kernel_size=(9,), stride=(1,), padding=same, dilation=(2,))\n",
       "        (2): TransposeLayer()\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ffn): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (14): ConvLayer(\n",
       "      (conv): Sequential(\n",
       "        (0): TransposeLayer()\n",
       "        (1): Conv1d(512, 512, kernel_size=(9,), stride=(1,), padding=same, dilation=(4,))\n",
       "        (2): TransposeLayer()\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ffn): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (15): ConvLayer(\n",
       "      (conv): Sequential(\n",
       "        (0): TransposeLayer()\n",
       "        (1): Conv1d(512, 512, kernel_size=(9,), stride=(1,), padding=same, dilation=(8,))\n",
       "        (2): TransposeLayer()\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ffn): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (16): ConvLayer(\n",
       "      (conv): Sequential(\n",
       "        (0): TransposeLayer()\n",
       "        (1): Conv1d(512, 512, kernel_size=(9,), stride=(1,), padding=same, dilation=(16,))\n",
       "        (2): TransposeLayer()\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ffn): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (17): ConvLayer(\n",
       "      (conv): Sequential(\n",
       "        (0): TransposeLayer()\n",
       "        (1): Conv1d(512, 512, kernel_size=(9,), stride=(1,), padding=same, dilation=(32,))\n",
       "        (2): TransposeLayer()\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ffn): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (18): ConvLayer(\n",
       "      (conv): Sequential(\n",
       "        (0): TransposeLayer()\n",
       "        (1): Conv1d(512, 512, kernel_size=(9,), stride=(1,), padding=same)\n",
       "        (2): TransposeLayer()\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ffn): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (19): ConvLayer(\n",
       "      (conv): Sequential(\n",
       "        (0): TransposeLayer()\n",
       "        (1): Conv1d(512, 512, kernel_size=(9,), stride=(1,), padding=same, dilation=(2,))\n",
       "        (2): TransposeLayer()\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ffn): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (20): ConvLayer(\n",
       "      (conv): Sequential(\n",
       "        (0): TransposeLayer()\n",
       "        (1): Conv1d(512, 512, kernel_size=(9,), stride=(1,), padding=same, dilation=(4,))\n",
       "        (2): TransposeLayer()\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ffn): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (21): ConvLayer(\n",
       "      (conv): Sequential(\n",
       "        (0): TransposeLayer()\n",
       "        (1): Conv1d(512, 512, kernel_size=(9,), stride=(1,), padding=same, dilation=(8,))\n",
       "        (2): TransposeLayer()\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ffn): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (22): ConvLayer(\n",
       "      (conv): Sequential(\n",
       "        (0): TransposeLayer()\n",
       "        (1): Conv1d(512, 512, kernel_size=(9,), stride=(1,), padding=same, dilation=(16,))\n",
       "        (2): TransposeLayer()\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ffn): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (23): ConvLayer(\n",
       "      (conv): Sequential(\n",
       "        (0): TransposeLayer()\n",
       "        (1): Conv1d(512, 512, kernel_size=(9,), stride=(1,), padding=same, dilation=(32,))\n",
       "        (2): TransposeLayer()\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ffn): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (24): ConvLayer(\n",
       "      (conv): Sequential(\n",
       "        (0): TransposeLayer()\n",
       "        (1): Conv1d(512, 512, kernel_size=(9,), stride=(1,), padding=same)\n",
       "        (2): TransposeLayer()\n",
       "        (3): GELU(approximate='none')\n",
       "        (4): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ffn): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained(model_path)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7471ad09-5ccb-4696-ac0c-7016657a0e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependency map generation functions\n",
    "\n",
    "nuc_table = {\"A\": 0, \"C\": 1, \"G\": 2, \"T\": 3}\n",
    "\n",
    "\n",
    "def mutate_sequence(seq):\n",
    "\n",
    "    seq = seq.upper()\n",
    "    mutated_sequences = {\"seq\": [], \"mutation_pos\": [], \"nuc\": [], \"var_nt_idx\": []}\n",
    "    mutated_sequences[\"seq\"].append(seq)\n",
    "    mutated_sequences[\"mutation_pos\"].append(-1)\n",
    "    mutated_sequences[\"nuc\"].append(\"real sequence\")\n",
    "    mutated_sequences[\"var_nt_idx\"].append(-1)\n",
    "\n",
    "    mutate_until_position = len(seq)\n",
    "\n",
    "    for i in range(mutate_until_position):\n",
    "        for nuc in [\"A\", \"C\", \"G\", \"T\"]:\n",
    "            if nuc != seq[i]:\n",
    "                mutated_sequences[\"seq\"].append(seq[:i] + nuc + seq[i + 1 :])\n",
    "                mutated_sequences[\"mutation_pos\"].append(i)\n",
    "                mutated_sequences[\"nuc\"].append(nuc)\n",
    "                mutated_sequences[\"var_nt_idx\"].append(nuc_table[nuc])\n",
    "\n",
    "    mutations_df = pd.DataFrame(mutated_sequences)\n",
    "\n",
    "    return mutations_df\n",
    "\n",
    "\n",
    "def create_dataloader(dataset, batch_size=64, rolling_masking=False):\n",
    "\n",
    "    ds = Dataset.from_pandas(dataset[[\"seq\"]])\n",
    "    tok_ds = ds.map(lambda x: tokenizer(list(x[\"seq\"])), batched=False, num_proc=20)\n",
    "    rem_tok_ds = tok_ds.remove_columns(\"seq\")\n",
    "\n",
    "    data_collator = DefaultDataCollator()\n",
    "\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        rem_tok_ds,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=4,\n",
    "        shuffle=False,\n",
    "        collate_fn=data_collator,\n",
    "    )\n",
    "\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3cd2170-f395-4717-aea3-a504a6924811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "      <th>mutation_pos</th>\n",
       "      <th>nuc</th>\n",
       "      <th>var_nt_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CGGGTTAAAAATCTAGTTGTTATTATTAAAGGAAATAAAATATCCT...</td>\n",
       "      <td>-1</td>\n",
       "      <td>real sequence</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AGGGTTAAAAATCTAGTTGTTATTATTAAAGGAAATAAAATATCCT...</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GGGGTTAAAAATCTAGTTGTTATTATTAAAGGAAATAAAATATCCT...</td>\n",
       "      <td>0</td>\n",
       "      <td>G</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TGGGTTAAAAATCTAGTTGTTATTATTAAAGGAAATAAAATATCCT...</td>\n",
       "      <td>0</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CAGGTTAAAAATCTAGTTGTTATTATTAAAGGAAATAAAATATCCT...</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2096</th>\n",
       "      <td>CGGGTTAAAAATCTAGTTGTTATTATTAAAGGAAATAAAATATCCT...</td>\n",
       "      <td>698</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097</th>\n",
       "      <td>CGGGTTAAAAATCTAGTTGTTATTATTAAAGGAAATAAAATATCCT...</td>\n",
       "      <td>698</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>CGGGTTAAAAATCTAGTTGTTATTATTAAAGGAAATAAAATATCCT...</td>\n",
       "      <td>699</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099</th>\n",
       "      <td>CGGGTTAAAAATCTAGTTGTTATTATTAAAGGAAATAAAATATCCT...</td>\n",
       "      <td>699</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2100</th>\n",
       "      <td>CGGGTTAAAAATCTAGTTGTTATTATTAAAGGAAATAAAATATCCT...</td>\n",
       "      <td>699</td>\n",
       "      <td>G</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2101 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    seq  mutation_pos  \\\n",
       "0     CGGGTTAAAAATCTAGTTGTTATTATTAAAGGAAATAAAATATCCT...            -1   \n",
       "1     AGGGTTAAAAATCTAGTTGTTATTATTAAAGGAAATAAAATATCCT...             0   \n",
       "2     GGGGTTAAAAATCTAGTTGTTATTATTAAAGGAAATAAAATATCCT...             0   \n",
       "3     TGGGTTAAAAATCTAGTTGTTATTATTAAAGGAAATAAAATATCCT...             0   \n",
       "4     CAGGTTAAAAATCTAGTTGTTATTATTAAAGGAAATAAAATATCCT...             1   \n",
       "...                                                 ...           ...   \n",
       "2096  CGGGTTAAAAATCTAGTTGTTATTATTAAAGGAAATAAAATATCCT...           698   \n",
       "2097  CGGGTTAAAAATCTAGTTGTTATTATTAAAGGAAATAAAATATCCT...           698   \n",
       "2098  CGGGTTAAAAATCTAGTTGTTATTATTAAAGGAAATAAAATATCCT...           699   \n",
       "2099  CGGGTTAAAAATCTAGTTGTTATTATTAAAGGAAATAAAATATCCT...           699   \n",
       "2100  CGGGTTAAAAATCTAGTTGTTATTATTAAAGGAAATAAAATATCCT...           699   \n",
       "\n",
       "                nuc  var_nt_idx  \n",
       "0     real sequence          -1  \n",
       "1                 A           0  \n",
       "2                 G           2  \n",
       "3                 T           3  \n",
       "4                 A           0  \n",
       "...             ...         ...  \n",
       "2096              C           1  \n",
       "2097              T           3  \n",
       "2098              A           0  \n",
       "2099              C           1  \n",
       "2100              G           2  \n",
       "\n",
       "[2101 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = mutate_sequence(seq)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9954111-5c07-48da-b4b9-6e942c52e76a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['seq'],\n",
       "    num_rows: 2101\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = Dataset.from_pandas(dataset[[\"seq\"]])\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f456e297-d596-4032-b983-91a8f7335fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c2eed321ea94d0c9769378d97b7af03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=20):   0%|          | 0/2101 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['seq', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 2101\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_ds = ds.map(lambda x: tokenizer(list(x[\"seq\"])), batched=False, num_proc=20)\n",
    "tok_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d85229df-56a2-47d1-926b-1718a3f7d421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93ad7e1f65164231a3c23ab2e3a7ecc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=20):   0%|          | 0/2101 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f9881445b80>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader = create_dataloader(dataset, batch_size=1)\n",
    "data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "978fea16-02dc-4f47-91b2-0ccf99c7125e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[4],\n",
       "         [5],\n",
       "         [5],\n",
       "         [5],\n",
       "         [6],\n",
       "         [6],\n",
       "         [3],\n",
       "         [3],\n",
       "         [3],\n",
       "         [3],\n",
       "         [3],\n",
       "         [6],\n",
       "         [4],\n",
       "         [6],\n",
       "         [3],\n",
       "         [5],\n",
       "         [6],\n",
       "         [6],\n",
       "         [5],\n",
       "         [6],\n",
       "         [6],\n",
       "         [3],\n",
       "         [6],\n",
       "         [6],\n",
       "         [3],\n",
       "         [6],\n",
       "         [6],\n",
       "         [3],\n",
       "         [3],\n",
       "         [3],\n",
       "         [5],\n",
       "         [5],\n",
       "         [3],\n",
       "         [3],\n",
       "         [3],\n",
       "         [6],\n",
       "         [3],\n",
       "         [3],\n",
       "         [3],\n",
       "         [3],\n",
       "         [6],\n",
       "         [3],\n",
       "         [6],\n",
       "         [4],\n",
       "         [4],\n",
       "         [6],\n",
       "         [4],\n",
       "         [3],\n",
       "         [6],\n",
       "         [3],\n",
       "         [3],\n",
       "         [3],\n",
       "         [3],\n",
       "         [4],\n",
       "         [3],\n",
       "         [3],\n",
       "         [6],\n",
       "         [6],\n",
       "         [6],\n",
       "         [5],\n",
       "         [6],\n",
       "         [6],\n",
       "         [5],\n",
       "         [6],\n",
       "         [3],\n",
       "         [3],\n",
       "         [6],\n",
       "         [4],\n",
       "         [6],\n",
       "         [3],\n",
       "         [6],\n",
       "         [4],\n",
       "         [6],\n",
       "         [6],\n",
       "         [6],\n",
       "         [5],\n",
       "         [5],\n",
       "         [5],\n",
       "         [4],\n",
       "         [6],\n",
       "         [3],\n",
       "         [3],\n",
       "         [6],\n",
       "         [5],\n",
       "         [6],\n",
       "         [6],\n",
       "         [4],\n",
       "         [6],\n",
       "         [6],\n",
       "         [3],\n",
       "         [6],\n",
       "         [4],\n",
       "         [4],\n",
       "         [6],\n",
       "         [3],\n",
       "         [4],\n",
       "         [3],\n",
       "         [3],\n",
       "         [5],\n",
       "         [3],\n",
       "         [4],\n",
       "         [5],\n",
       "         [3],\n",
       "         [3],\n",
       "         [4],\n",
       "         [4],\n",
       "         [4],\n",
       "         [6],\n",
       "         [5],\n",
       "         [3],\n",
       "         [4],\n",
       "         [4],\n",
       "         [5],\n",
       "         [6],\n",
       "         [3],\n",
       "         [6],\n",
       "         [6],\n",
       "         [4],\n",
       "         [5],\n",
       "         [6],\n",
       "         [4],\n",
       "         [5],\n",
       "         [6],\n",
       "         [3],\n",
       "         [5],\n",
       "         [3],\n",
       "         [3],\n",
       "         [3],\n",
       "         [3],\n",
       "         [3],\n",
       "         [3],\n",
       "         [3],\n",
       "         [3],\n",
       "         [6],\n",
       "         [6],\n",
       "         [5],\n",
       "         [4],\n",
       "         [6],\n",
       "         [6],\n",
       "         [4],\n",
       "         [5],\n",
       "         [3],\n",
       "         [6],\n",
       "         [4],\n",
       "         [4],\n",
       "         [4],\n",
       "         [3],\n",
       "         [6],\n",
       "         [4],\n",
       "         [3],\n",
       "         [6],\n",
       "         [6],\n",
       "         [5],\n",
       "         [3],\n",
       "         [5],\n",
       "         [6],\n",
       "         [6],\n",
       "         [4],\n",
       "         [3],\n",
       "         [3],\n",
       "         [6],\n",
       "         [3],\n",
       "         [3],\n",
       "         [6],\n",
       "         [4],\n",
       "         [5],\n",
       "         [5],\n",
       "         [4],\n",
       "         [5],\n",
       "         [4],\n",
       "         [3],\n",
       "         [4],\n",
       "         [3],\n",
       "         [3],\n",
       "         [3],\n",
       "         [5],\n",
       "         [5],\n",
       "         [4],\n",
       "         [4],\n",
       "         [5],\n",
       "         [3],\n",
       "         [6],\n",
       "         [6],\n",
       "         [4],\n",
       "         [3],\n",
       "         [6],\n",
       "         [3],\n",
       "         [3],\n",
       "         [3],\n",
       "         [3],\n",
       "         [3],\n",
       "         [4],\n",
       "         [6],\n",
       "         [4],\n",
       "         [6],\n",
       "         [3],\n",
       "         [5],\n",
       "         [5],\n",
       "         [4],\n",
       "         [4],\n",
       "         [4],\n",
       "         [3],\n",
       "         [6],\n",
       "         [6],\n",
       "         [3],\n",
       "         [3],\n",
       "         [3],\n",
       "         [5],\n",
       "         [6],\n",
       "         [3],\n",
       "         [3],\n",
       "         [3],\n",
       "         [5],\n",
       "         [4],\n",
       "         [4],\n",
       "         [4],\n",
       "         [3],\n",
       "         [6],\n",
       "         [6],\n",
       "         [4],\n",
       "         [6],\n",
       "         [4],\n",
       "         [3],\n",
       "         [3],\n",
       "         [4],\n",
       "         [4],\n",
       "         [4],\n",
       "         [6],\n",
       "         [3],\n",
       "         [6],\n",
       "         [4],\n",
       "         [4],\n",
       "         [3],\n",
       "         [5],\n",
       "         [6],\n",
       "         [4],\n",
       "         [6],\n",
       "         [4],\n",
       "         [4],\n",
       "         [4],\n",
       "         [6],\n",
       "         [5],\n",
       "         [6],\n",
       "         [3],\n",
       "         [6],\n",
       "         [3],\n",
       "         [6],\n",
       "         [3],\n",
       "         [6],\n",
       "         [3],\n",
       "         [6],\n",
       "         [3],\n",
       "         [6],\n",
       "         [6],\n",
       "         [6],\n",
       "         [3],\n",
       "         [4],\n",
       "         [5],\n",
       "         [3],\n",
       "         [4],\n",
       "         [3],\n",
       "         [4],\n",
       "         [4],\n",
       "         [3],\n",
       "         [3],\n",
       "         [4],\n",
       "         [4],\n",
       "         [4],\n",
       "         [3],\n",
       "         [5],\n",
       "         [4],\n",
       "         [5],\n",
       "         [6],\n",
       "         [6],\n",
       "         [5],\n",
       "         [3],\n",
       "         [6],\n",
       "         [3],\n",
       "         [6],\n",
       "         [6],\n",
       "         [6],\n",
       "         [3],\n",
       "         [3],\n",
       "         [6],\n",
       "         [6],\n",
       "         [6],\n",
       "         [6],\n",
       "         [4],\n",
       "         [6],\n",
       "         [6],\n",
       "         [4],\n",
       "         [3],\n",
       "         [5],\n",
       "         [6],\n",
       "         [4],\n",
       "         [3],\n",
       "         [5],\n",
       "         [3],\n",
       "         [5],\n",
       "         [3],\n",
       "         [6],\n",
       "         [6],\n",
       "         [6],\n",
       "         [4],\n",
       "         [5],\n",
       "         [3],\n",
       "         [3],\n",
       "         [3],\n",
       "         [4],\n",
       "         [4],\n",
       "         [4],\n",
       "         [6],\n",
       "         [3],\n",
       "         [5],\n",
       "         [6],\n",
       "         [4],\n",
       "         [5],\n",
       "         [3],\n",
       "         [6],\n",
       "         [6],\n",
       "         [6],\n",
       "         [4],\n",
       "         [5],\n",
       "         [3],\n",
       "         [5],\n",
       "         [3],\n",
       "         [6],\n",
       "         [4],\n",
       "         [4],\n",
       "         [3],\n",
       "         [3],\n",
       "         [4],\n",
       "         [6],\n",
       "         [3],\n",
       "         [3],\n",
       "         [4],\n",
       "         [6],\n",
       "         [4],\n",
       "         [6],\n",
       "         [5],\n",
       "         [4],\n",
       "         [6],\n",
       "         [4],\n",
       "         [4],\n",
       "         [6],\n",
       "         [6],\n",
       "         [3],\n",
       "         [6],\n",
       "         [4],\n",
       "         [6],\n",
       "         [4],\n",
       "         [3],\n",
       "         [5],\n",
       "         [5],\n",
       "         [6],\n",
       "         [3],\n",
       "         [3],\n",
       "         [3],\n",
       "         [3],\n",
       "         [6],\n",
       "         [6],\n",
       "         [4],\n",
       "         [6],\n",
       "         [4],\n",
       "         [5],\n",
       "         [4],\n",
       "         [6],\n",
       "         [4],\n",
       "         [5],\n",
       "         [3],\n",
       "         [5],\n",
       "         [3],\n",
       "         [3],\n",
       "         [4],\n",
       "         [6],\n",
       "         [4],\n",
       "         [3],\n",
       "         [3],\n",
       "         [6],\n",
       "         [6],\n",
       "         [5],\n",
       "         [4],\n",
       "         [6],\n",
       "         [6],\n",
       "         [3],\n",
       "         [6],\n",
       "         [4],\n",
       "         [4],\n",
       "         [3],\n",
       "         [3],\n",
       "         [3],\n",
       "         [5],\n",
       "         [6],\n",
       "         [6],\n",
       "         [4],\n",
       "         [4],\n",
       "         [3],\n",
       "         [3],\n",
       "         [4],\n",
       "         [6],\n",
       "         [5],\n",
       "         [3],\n",
       "         [3],\n",
       "         [5],\n",
       "         [3],\n",
       "         [6],\n",
       "         [5],\n",
       "         [4],\n",
       "         [6],\n",
       "         [6],\n",
       "         [6],\n",
       "         [4],\n",
       "         [4],\n",
       "         [6],\n",
       "         [3],\n",
       "         [4],\n",
       "         [6],\n",
       "         [5],\n",
       "         [3],\n",
       "         [3],\n",
       "         [6],\n",
       "         [4],\n",
       "         [6],\n",
       "         [6],\n",
       "         [3],\n",
       "         [5],\n",
       "         [5],\n",
       "         [6],\n",
       "         [6],\n",
       "         [3],\n",
       "         [3],\n",
       "         [6],\n",
       "         [5],\n",
       "         [6],\n",
       "         [6],\n",
       "         [6],\n",
       "         [6],\n",
       "         [5],\n",
       "         [5],\n",
       "         [3],\n",
       "         [6],\n",
       "         [6],\n",
       "         [6],\n",
       "         [5],\n",
       "         [5],\n",
       "         [3],\n",
       "         [3],\n",
       "         [6],\n",
       "         [4],\n",
       "         [6],\n",
       "         [6],\n",
       "         [3],\n",
       "         [4],\n",
       "         [4],\n",
       "         [4],\n",
       "         [5],\n",
       "         [3],\n",
       "         [3],\n",
       "         [3],\n",
       "         [6],\n",
       "         [6],\n",
       "         [6],\n",
       "         [4],\n",
       "         [6],\n",
       "         [4],\n",
       "         [6],\n",
       "         [5],\n",
       "         [4],\n",
       "         [3],\n",
       "         [5],\n",
       "         [4],\n",
       "         [6],\n",
       "         [6],\n",
       "         [5],\n",
       "         [6],\n",
       "         [6],\n",
       "         [5],\n",
       "         [3],\n",
       "         [3],\n",
       "         [6],\n",
       "         [6],\n",
       "         [6],\n",
       "         [5],\n",
       "         [4],\n",
       "         [5],\n",
       "         [3],\n",
       "         [3],\n",
       "         [5],\n",
       "         [6],\n",
       "         [3],\n",
       "         [6],\n",
       "         [5],\n",
       "         [5],\n",
       "         [5],\n",
       "         [3],\n",
       "         [5],\n",
       "         [3],\n",
       "         [4],\n",
       "         [5],\n",
       "         [4],\n",
       "         [6],\n",
       "         [3],\n",
       "         [5],\n",
       "         [3],\n",
       "         [5],\n",
       "         [3],\n",
       "         [4],\n",
       "         [3],\n",
       "         [3],\n",
       "         [4],\n",
       "         [5],\n",
       "         [3],\n",
       "         [3],\n",
       "         [5],\n",
       "         [4],\n",
       "         [4],\n",
       "         [6],\n",
       "         [3],\n",
       "         [4],\n",
       "         [5],\n",
       "         [3],\n",
       "         [5],\n",
       "         [5],\n",
       "         [3],\n",
       "         [5],\n",
       "         [5],\n",
       "         [3],\n",
       "         [5],\n",
       "         [4],\n",
       "         [6],\n",
       "         [4],\n",
       "         [6],\n",
       "         [6],\n",
       "         [5],\n",
       "         [5],\n",
       "         [3],\n",
       "         [4],\n",
       "         [6],\n",
       "         [3],\n",
       "         [6],\n",
       "         [5],\n",
       "         [3],\n",
       "         [3],\n",
       "         [5],\n",
       "         [3],\n",
       "         [3],\n",
       "         [5],\n",
       "         [3],\n",
       "         [3],\n",
       "         [5],\n",
       "         [3],\n",
       "         [4],\n",
       "         [5],\n",
       "         [3],\n",
       "         [5],\n",
       "         [3],\n",
       "         [3],\n",
       "         [5],\n",
       "         [5],\n",
       "         [6],\n",
       "         [4],\n",
       "         [4],\n",
       "         [4],\n",
       "         [3],\n",
       "         [5],\n",
       "         [3],\n",
       "         [6],\n",
       "         [6],\n",
       "         [4],\n",
       "         [6],\n",
       "         [5],\n",
       "         [5],\n",
       "         [3],\n",
       "         [3],\n",
       "         [3],\n",
       "         [4],\n",
       "         [3],\n",
       "         [3],\n",
       "         [3],\n",
       "         [5],\n",
       "         [6],\n",
       "         [6],\n",
       "         [3],\n",
       "         [3],\n",
       "         [4],\n",
       "         [5],\n",
       "         [5],\n",
       "         [4],\n",
       "         [5],\n",
       "         [3],\n",
       "         [3],\n",
       "         [5],\n",
       "         [4],\n",
       "         [6],\n",
       "         [5],\n",
       "         [6],\n",
       "         [5],\n",
       "         [3],\n",
       "         [3],\n",
       "         [3],\n",
       "         [3],\n",
       "         [3],\n",
       "         [5],\n",
       "         [6],\n",
       "         [5],\n",
       "         [3],\n",
       "         [5],\n",
       "         [6],\n",
       "         [6],\n",
       "         [6],\n",
       "         [6],\n",
       "         [3],\n",
       "         [6],\n",
       "         [5],\n",
       "         [5],\n",
       "         [6],\n",
       "         [6],\n",
       "         [6],\n",
       "         [4],\n",
       "         [4],\n",
       "         [6],\n",
       "         [4],\n",
       "         [5],\n",
       "         [3],\n",
       "         [6],\n",
       "         [3],\n",
       "         [6],\n",
       "         [5],\n",
       "         [6],\n",
       "         [6],\n",
       "         [6],\n",
       "         [4],\n",
       "         [3],\n",
       "         [6],\n",
       "         [5],\n",
       "         [6],\n",
       "         [3],\n",
       "         [6],\n",
       "         [3],\n",
       "         [4],\n",
       "         [6],\n",
       "         [3],\n",
       "         [4],\n",
       "         [6],\n",
       "         [5],\n",
       "         [6],\n",
       "         [5],\n",
       "         [6],\n",
       "         [5],\n",
       "         [6],\n",
       "         [6],\n",
       "         [6],\n",
       "         [3],\n",
       "         [3],\n",
       "         [3],\n",
       "         [6],\n",
       "         [6],\n",
       "         [6],\n",
       "         [5],\n",
       "         [6],\n",
       "         [4],\n",
       "         [5],\n",
       "         [3],\n",
       "         [6],\n",
       "         [6],\n",
       "         [4],\n",
       "         [6],\n",
       "         [6],\n",
       "         [3],\n",
       "         [5],\n",
       "         [3],\n",
       "         [6],\n",
       "         [6],\n",
       "         [3],\n",
       "         [4],\n",
       "         [6],\n",
       "         [3],\n",
       "         [4],\n",
       "         [6],\n",
       "         [6],\n",
       "         [5],\n",
       "         [3],\n",
       "         [6],\n",
       "         [3],\n",
       "         [3],\n",
       "         [4],\n",
       "         [3],\n",
       "         [3],\n",
       "         [5],\n",
       "         [6],\n",
       "         [3],\n",
       "         [5],\n",
       "         [4],\n",
       "         [3],\n",
       "         [5],\n",
       "         [6],\n",
       "         [3],\n",
       "         [6],\n",
       "         [5],\n",
       "         [6]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(data_loader))['input_ids']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
